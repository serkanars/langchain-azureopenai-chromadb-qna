{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\serkan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\serkan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\serkan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\serkan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\serkan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\serkan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\serkan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\SERKAN\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install langchain==0.1 langchain_openai python-dotenv chromadb docx2txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv,dotenv_values\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(dotenv_values(\"azureConfig.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_TYPE\"] = config[\"OPENAI_API_TYPE\"]\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = config[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"OPENAI_API_KEY\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"] = config[\"OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deployment_name = os.getenv(\"gpt-35-turbo\")\n",
    "embedding_deployment_name = os.getenv(\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Docx2txtLoader(r\"C:\\Users\\SERKAN\\Desktop\\DİLARA/Yeni Microsoft Word Belgesi2.docx\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "print(len(all_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = AzureOpenAIEmbeddings(\n",
    "    deployment=embedding_deployment_name,\n",
    "    )\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Emekliye ayırma planlaması nasıl olur\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=model_deployment_name,\n",
    "    model_name = \"test\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Emekliye ayırma planlaması, iş sürekliliği planları, geri çekilme planı, yapılandırma ve yeniden kurulum prosedürleri gibi ayrıntılı adımlar içermelidir. Emeklilik öncesi iş süreci belgelenmeli ve sürecin perspektiflerinden anlaşılmalıdır. Emeklilik infazının zamanlaması dikkatle düşünülmeli ve program dahil edilmelidir.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Don't try to make up the answer, only use the context to answer the question.\n",
    "The pieces of context refer to the this word file.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 12})\n",
    "\n",
    "qa_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "response = qa_chain.invoke(question)\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
